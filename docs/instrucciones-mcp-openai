## Resumen de mejoras recientes en la conectividad MCP de OpenAI

OpenAI ha añadido **soporte nativo para servidores MCP remotos** en su Responses API, permitiendo a los desarrolladores conectar modelos a cualquier servidor MCP con pocas líneas de código ([OpenAI][1]).
Además de MCP, la Responses API ahora incluye **modos en segundo plano** para tareas largas, **resúmenes de razonamiento** y **elementos de razonamiento cifrados**, mejorando fiabilidad, visibilidad y privacidad para empresas ([OpenAI][1]).
En paralelo, el **Agents SDK** se actualizó en marzo de 2025 para exponer MCP de forma robusta, de manera que tanto el SDK como la Responses API compartan un estándar unificado para descubrimiento e invocación de herramientas ([Comunidad OpenAI][2]).
OpenAI también ha adoptado un **marco de autorización OAuth 2.1**, mejorando la seguridad en comunicaciones agente-servidor, y ha introducido un **transporte HTTP “streamable”** que reemplaza HTTP+SSE para flujos bidireccionales de baja latencia ([Techstrong.ai][3]).
Se añadió **JSON-RPC batching**, permitiendo agrupar múltiples invocaciones de herramienta en una sola petición para reducir latencia y mejorar eficiencia ([Techstrong.ai][3]).
Estos avances se hicieron públicos el 21 de mayo de 2025, coincidiendo con la disponibilidad de GPT-4.1 y las series o3/o4-mini en la Responses API ([VentureBeat][4]).

---

## Instrucciones para implementar las mejoras MCP en tu herramienta

### 1. Actualizar dependencias

* Instala la última versión de la **Responses API client** y el **Agents SDK ≥ 0.7**, donde se liberó el soporte completo para servidores MCP remotos ([OpenAI][1]).
* Si usas Node.js:

  ```bash
  npm install openai @openai/agents-sdk
  ```
* Si usas Python:

  ```bash
  pip install openai openai-agents
  ```

### 2. Configurar la conexión MCP

Define en tu configuración la URL de tu servidor MCP y, de ser necesario, las credenciales OAuth 2.1:

```jsonc
{
  "mcpServer": {
    "url": "wss://tu-servidor-mcp.com/stream",
    "auth": {
      "type": "oauth2",
      "token_url": "https://auth.ejemplo.com/token",
      "client_id": "...",
      "client_secret": "..."
    }
  }
}
```

Este esquema aprovecha el **marco OAuth 2.1** para proteger el canal agente-servidor ([Techstrong.ai][3]).

### 3. Descubrir herramientas (list\_tools)

Al iniciar el chat, envía un mensaje MCP para listar las herramientas disponibles:

```json
{
  "protocol": "mcp",
  "version": 1,
  "action": "list_tools"
}
```

El servidor MCP debe responder con un array de objetos `{ tool_name, description, input_schema }` ([Wikipedia][5]).

### 4. Invocar herramientas (invoke)

Cuando el modelo decida usar una herramienta, envía:

```json
{
  "protocol": "mcp",
  "version": 1,
  "action": "invoke",
  "tool_name": "mi_herramienta",
  "arguments": { /* según input_schema */ }
}
```

Por ejemplo, para búsqueda web:

````json
{
  "protocol": "mcp",
  "version": 1,
  "action": "invoke",
  "tool_name": "search",
  "arguments": { "query": "novedades OpenAI MCP", "limit": 5 }
}
``` :contentReference[oaicite:9]{index=9}.  

### 5. Manejar respuestas y errores  
El servidor MCP debe devolver:
```json
{
  "protocol": "mcp",
  "version": 1,
  "status": "success",
  "tool_name": "search",
  "results": [ /* datos */ ]
}
````

o bien:

```json
{
  "protocol": "mcp",
  "version": 1,
  "status": "error",
  "error": "Descripción del error"
}
```

Implementa lógica de reintento y back-off para gestionar errores de transporte o de herramienta ([Tray.ai][6]).

### 6. Integrar en el flujo de ChatService

En tu `ChatService`, sustituye la simulación interna por:

1. **Open WebSocket** al `mcpServer.url`.
2. **Listar herramientas** al conectar y almacenar los schemas.
3. **Interceptar mensajes** del usuario: analizar si el modelo sugiere una llamada a herramienta (puede usar `"tool_call"` en la respuesta de la Responses API).
4. **Enviar `invoke`** por WebSocket y combinar los resultados en el prompt para la siguiente ronda de chat ([Medium][7]).

### 7. Ejemplo mínimo en Node.js

```javascript
import { Agent } from "@openai/agents-sdk";
import WebSocket from "ws";

async function runChat(message) {
  // 1. Conectar al servidor MCP
  const ws = new WebSocket("wss://tu-servidor-mcp.com/stream");
  await once(ws, "open");

  // 2. Listar herramientas
  ws.send(JSON.stringify({ protocol:"mcp",version:1,action:"list_tools" }));
  const toolsMsg = await once(ws, "message");
  const tools = JSON.parse(toolsMsg).tools;

  // 3. Crear agente con referencia al WebSocket
  const agent = new Agent({
    name: "ChatBot",
    instructions: "Usa las herramientas disponibles.",
    mcpServers: [{ ws, tools }]
  });

  // 4. Ejecutar chat y stream de respuestas
  for await (const chunk of agent.runStream({ model:"o4-mini" }, message)) {
    process.stdout.write(chunk);
  }
}
```

### 8. Pruebas recomendadas

* **Validación de list\_tools**: comprueba que recibes el listado correcto.
* **Caso de uso simple**: invoca `search("qué es MCP")` y verifica resultados.
* **Mecanismos de fallback**: si el servidor cae, muestra un mensaje amigable al usuario.

Con estos pasos podrás aprovechar **todas las mejoras recientes de OpenAI en la conectividad MCP** y conectar tus propios servidores MCP para que el modelo invoque eficazmente sus herramientas.

[1]: https://openai.com/index/new-tools-and-features-in-the-responses-api/?utm_source=chatgpt.com "New tools and features in the Responses API - OpenAI"
[2]: https://community.openai.com/t/introducing-support-for-remote-mcp-servers-image-generation-code-interpreter-and-more-in-the-responses-api/1266973?utm_source=chatgpt.com "Introducing support for remote MCP servers, image generation ..."
[3]: https://techstrong.ai/aiops/model-context-protocol-the-new-standard-for-ai-interoperability/?utm_source=chatgpt.com "Model Context Protocol: The New Standard for AI Interoperability"
[4]: https://venturebeat.com/programming-development/openai-updates-its-new-responses-api-rapidly-with-mcp-support-gpt-4o-native-image-gen-and-more-enterprise-features/?utm_source=chatgpt.com "OpenAI updates its new Responses API rapidly with MCP support ..."
[5]: https://en.wikipedia.org/wiki/Model_Context_Protocol?utm_source=chatgpt.com "Model Context Protocol"
[6]: https://tray.ai/blog/model-context-protocol-mcp?utm_source=chatgpt.com "Model Context Protocol: Game changer or just hype? - Tray.ai"
[7]: https://medium.com/%40Micheal-Lanham/the-model-context-protocol-mcp-revolution-supercharging-openai-agents-with-universal-tool-access-5c5c60be524f?utm_source=chatgpt.com "The Model Context Protocol (MCP) Revolution: Supercharging ..."
